{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### AND Gate Classification\n",
        "Scenario:\n",
        "\n",
        "You are tasked with building a simple neural network to simulate an AND gate using a Single Layer Perceptron. The AND gate outputs 1 only if both inputs are 1; otherwise, it outputs 0.\n",
        "\n",
        "Lab Task: Implement a Single Layer Perceptron using Python in Google Colab to classify the output of an AND gate given two binary inputs (0 or 1). Follow these steps:\n",
        "\n",
        "Create a dataset representing the truth table of the AND gate.\n",
        "\n",
        "Define the perceptron model with one neuron, including the activation function and weights initialization(Try both random weights and defined weights).\n",
        "Train the perceptron using a suitable learning algorithm (e.g., gradient descent).\n",
        "\n",
        "Test the model with all possible input combinations and display the results."
      ],
      "metadata": {
        "id": "i1JuGrayjfxx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLh6bBBOh9Dk",
        "outputId": "38c41220-9a3e-4526-8d3b-a8147c5b20c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter initial weights (comma separated): 1.2,7.8\n",
            "Enter initial bias: 0.9\n",
            "\n",
            "Epoch 1\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [1.2 7.8], Bias: 0.8\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [1.2 7.7], Bias: 0.7\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 0, Weights: [1.1 7.7], Bias: 0.6\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [1.1 7.7], Bias: 0.6\n",
            "\n",
            "Epoch 2\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [1.1 7.7], Bias: 0.5\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [1.1 7.6], Bias: 0.4\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 0, Weights: [1.  7.6], Bias: 0.3\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [1.  7.6], Bias: 0.3\n",
            "\n",
            "Epoch 3\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [1.  7.6], Bias: 0.2\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [1.  7.5], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 0, Weights: [0.9 7.5], Bias: 0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.9 7.5], Bias: 0.0\n",
            "\n",
            "Epoch 4\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.9 7.5], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [0.9 7.4], Bias: -0.2\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 0, Weights: [0.8 7.4], Bias: -0.3\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.8 7.4], Bias: -0.3\n",
            "\n",
            "Epoch 5\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.8 7.4], Bias: -0.3\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [0.8 7.3], Bias: -0.4\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 0, Weights: [0.7 7.3], Bias: -0.5\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.7 7.3], Bias: -0.5\n",
            "\n",
            "Epoch 6\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.7 7.3], Bias: -0.5\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [0.7 7.2], Bias: -0.6\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 0, Weights: [0.6 7.2], Bias: -0.7\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.6 7.2], Bias: -0.7\n",
            "\n",
            "Epoch 7\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 7.2], Bias: -0.7\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [0.6 7.1], Bias: -0.8\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 7.1], Bias: -0.8\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.6 7.1], Bias: -0.8\n",
            "\n",
            "Epoch 8\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 7.1], Bias: -0.8\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [0.6 7. ], Bias: -0.9\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 7. ], Bias: -0.9\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.6 7. ], Bias: -0.9\n",
            "\n",
            "Epoch 9\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 7. ], Bias: -0.9\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [0.6 6.9], Bias: -1.0\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 6.9], Bias: -1.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.6 6.9], Bias: -1.0\n",
            "\n",
            "Epoch 10\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 6.9], Bias: -1.0\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 0, Weights: [0.6 6.8], Bias: -1.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 0, Weights: [0.6 6.8], Bias: -1.1\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.6 6.8], Bias: -1.1\n",
            "\n",
            "Testing AND Gate Perceptron:\n",
            "Input: [0 0], Predicted Output: 0\n",
            "Input: [0 1], Predicted Output: 1\n",
            "Input: [1 0], Predicted Output: 0\n",
            "Input: [1 1], Predicted Output: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step Activation Function\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Perceptron Model\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1, epochs=10, weights=None, bias=None):\n",
        "\n",
        "        if weights is not None:\n",
        "            self.weights = np.array(weights)\n",
        "        else:\n",
        "            self.weights = np.random.rand(input_size)\n",
        "\n",
        "        if bias is not None:\n",
        "            self.bias = bias  # Treat bias as a scalar, no need for array\n",
        "        else:\n",
        "            self.bias = np.random.rand(1)[0]  # Initialize bias as a scalar\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    # Predict output for given inputs\n",
        "    def predict(self, inputs):\n",
        "        linear_output = np.dot(inputs, self.weights) + self.bias\n",
        "        return step_function(linear_output)\n",
        "\n",
        "    # Train the model\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            all_correct = True  # Flag to track if all predictions are correct\n",
        "            print(f\"\\nEpoch {epoch + 1}\")\n",
        "            for inputs, target in zip(X, y):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = target - prediction\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.weights += self.learning_rate * error * inputs\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "                # Print current weights, bias, and output prediction (formatted to 2 decimal places)\n",
        "                print(f\"Input: {inputs}, Predicted Output: {prediction}, Actual Output: {target}, \"\n",
        "                      f\"Weights: {np.round(self.weights, 2)}, Bias: {round(self.bias, 2)}\")\n",
        "\n",
        "                # If there's an error, set all_correct to False\n",
        "                if error != 0:\n",
        "                    all_correct = False\n",
        "\n",
        "            # If all predictions were correct, exit early\n",
        "            if all_correct:\n",
        "                print(f\"\\nTraining complete after epoch {epoch + 1} (All predictions correct).\")\n",
        "                break\n",
        "\n",
        "# Dataset: AND gate truth table\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs for AND gate\n",
        "y = np.array([0, 0, 0, 1])  # Corresponding outputs for AND gate\n",
        "\n",
        "# User input for initial weights and bias\n",
        "input_weights = [float(x) for x in input(\"Enter initial weights (comma separated): \").split(\",\")]\n",
        "input_bias = float(input(\"Enter initial bias: \"))\n",
        "\n",
        "# Initialize and train the perceptron with manual weights and bias\n",
        "perceptron = Perceptron(input_size=2, learning_rate=0.1, epochs=10, weights=input_weights, bias=input_bias)\n",
        "perceptron.train(X, y)\n",
        "\n",
        "# Test the perceptron\n",
        "print(\"\\nTesting AND Gate Perceptron:\")\n",
        "for inputs in X:\n",
        "    output = perceptron.predict(inputs)\n",
        "    print(f\"Input: {inputs}, Predicted Output: {output}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How do the weights and bias values change during training for the AND gate?\n",
        "\n",
        "During training, the weights and bias are adjusted after each prediction, based on the error between the predicted and actual outputs. Here's a summary of the changes:\n",
        "\n",
        "Weights: Initially, the weights were set to 1.2 and 7.8. After each incorrect prediction, the weights were adjusted by the error multiplied by the learning rate and input value. Over the epochs, the weights gradually decreased, converging to 0.6 and 6.8 after 10 epochs.\n",
        "\n",
        "Bias: The bias started at 0.9. It was adjusted similarly to the weights, and by the end of training, the bias decreased to -1.1.\n",
        "This gradual reduction in the weights and bias shows that the perceptron is attempting to minimize errors and refine its decision boundary over time."
      ],
      "metadata": {
        "id": "KEhYXilq1pLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Can the perceptron successfully learn the AND logic with a linear decision boundary?\n",
        "\n",
        "Yes, the perceptron can successfully learn the AND logic because the AND function is linearly separable. A linear decision boundary is sufficient to separate the outputs of the AND gate: it returns 1 only when both inputs are 1, and returns 0 otherwise. By adjusting the weights and bias, the perceptron finds the appropriate decision boundary that matches the expected outputs of the AND gate, as shown by the final results:\n",
        "\n",
        "The perceptron predicts the correct output (0) for inputs [0, 0], [0, 1], and [1, 0].\n",
        "It also correctly predicts the output (1) for inputs [1, 1].\n",
        "Thus, the perceptron successfully learns the AND logic with a linear decision boundary after sufficient training."
      ],
      "metadata": {
        "id": "GagMzTro1JSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OR Gate Classification\n",
        "Scenario:\n",
        "Your next task is to design a perceptron that mimics the behavior of an OR gate. The OR gate outputs 1 if at least one of its inputs is 1.\n",
        "Lab Task: Using Google Colab, create a Single Layer Perceptron to classify the output of an OR gate. Perform the following steps:\n",
        "Prepare the dataset for the OR gate's truth table.\n",
        "Define and initialize a Single Layer Perceptron model.\n",
        "Implement the training process and adjust the perceptron's weights.\n",
        "Validate the perceptron's performance with the OR gate input combinations."
      ],
      "metadata": {
        "id": "3ffWRT3Tyjmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step Activation Function\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Perceptron Model\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.5, epochs=10, weights=None, bias=None):\n",
        "        # Allow user to input weights and bias manually or initialize them randomly\n",
        "        if weights is not None:\n",
        "            self.weights = np.array(weights)\n",
        "        else:\n",
        "            self.weights = np.random.rand(input_size)\n",
        "\n",
        "        if bias is not None:\n",
        "            self.bias = bias\n",
        "        else:\n",
        "            self.bias = np.random.rand(1)[0]\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    # Predict output for given inputs\n",
        "    def predict(self, inputs):\n",
        "        linear_output = np.dot(inputs, self.weights) + self.bias\n",
        "        return step_function(linear_output)\n",
        "\n",
        "    # Train the model\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            all_correct = True  # Flag to track if all predictions are correct\n",
        "            print(f\"\\nEpoch {epoch + 1}\")\n",
        "            for inputs, target in zip(X, y):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = target - prediction\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.weights += self.learning_rate * error * inputs\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "                # Print current weights, bias, and output prediction (formatted to 2 decimal places)\n",
        "                print(f\"Input: {inputs}, Predicted Output: {prediction}, Actual Output: {target}, \"\n",
        "                      f\"Weights: {np.round(self.weights, 2)}, Bias: {round(self.bias, 2)}\")\n",
        "\n",
        "                # If there's an error, set all_correct to False\n",
        "                if error != 0:\n",
        "                    all_correct = False\n",
        "\n",
        "            # If all predictions were correct, exit early\n",
        "            if all_correct:\n",
        "                print(f\"\\nTraining complete after epoch {epoch + 1} (All predictions correct).\")\n",
        "                break\n",
        "\n",
        "# Dataset: OR gate truth table\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs for OR gate\n",
        "y = np.array([0, 1, 1, 1])  # Corresponding outputs for OR gate\n",
        "\n",
        "# User input for initial weights and bias\n",
        "input_weights = [float(x) for x in input(\"Enter initial weights (comma separated): \").split(\",\")]\n",
        "input_bias = float(input(\"Enter initial bias: \"))\n",
        "\n",
        "# Initialize and train the perceptron with manual weights and bias\n",
        "perceptron = Perceptron(input_size=2, learning_rate=0.1, epochs=10, weights=input_weights, bias=input_bias)\n",
        "perceptron.train(X, y)\n",
        "\n",
        "# Test the perceptron\n",
        "print(\"\\nTesting OR Gate Perceptron:\")\n",
        "for inputs in X:\n",
        "    output = perceptron.predict(inputs)\n",
        "    print(f\"Input: {inputs}, Predicted Output: {output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOnGhlPzuzvR",
        "outputId": "53fae223-b9d9-4b06-9c71-3fdf00b6fc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter initial weights (comma separated): 0.1, 0.9\n",
            "Enter initial bias: 0.6\n",
            "\n",
            "Epoch 1\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: 0.5\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.5\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.5\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.5\n",
            "\n",
            "Epoch 2\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: 0.4\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.4\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.4\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.4\n",
            "\n",
            "Epoch 3\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: 0.3\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.3\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.3\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.3\n",
            "\n",
            "Epoch 4\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: 0.2\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.2\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.2\n",
            "\n",
            "Epoch 5\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: 0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.1\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.1\n",
            "\n",
            "Epoch 6\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: 0.0\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.0\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: 0.0\n",
            "\n",
            "Epoch 7\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: -0.1\n",
            "\n",
            "Epoch 8\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: -0.1\n",
            "\n",
            "Training complete after epoch 8 (All predictions correct).\n",
            "\n",
            "Testing OR Gate Perceptron:\n",
            "Input: [0 0], Predicted Output: 0\n",
            "Input: [0 1], Predicted Output: 1\n",
            "Input: [1 0], Predicted Output: 1\n",
            "Input: [1 1], Predicted Output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What changes in the perceptron's weights are necessary to represent the OR gate logic?\n",
        "\n",
        "The initial weights are [0.1, 0.9], and the initial bias is 0.6.\n",
        "Throughout the epochs, the weights remain constant at [0.1, 0.9], while the bias reduces gradually after each incorrect prediction until it reaches -0.1.\n",
        "The key aspect of learning the OR gate logic lies in the adjustment of the bias. In this case, the perceptron successfully learns the OR gate by adjusting the bias to -0.1 after 8 epochs, which allows it to classify all the inputs correctly.\n",
        "\n",
        "Thus, the necessary changes to represent the OR gate logic are primarily in the bias value. The bias needs to be reduced so that the linear combination of the weights and inputs results in correct outputs for all the OR gate's input-output pairs.\n",
        "\n"
      ],
      "metadata": {
        "id": "-RA6ArRy3Q1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How does the linear decision boundary look for the OR gate classification?\n",
        "In the case of a 2-input OR gate, the perceptron defines a linear decision boundary in a 2D plane (representing the inputs x1 and x2):\n",
        "\n",
        "The OR gate returns 1 when either x1 or x2 (or both) are 1.\n",
        "It returns 0 only when both inputs are 0."
      ],
      "metadata": {
        "id": "yT4RE4ee32F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AND-NOT Gate Classification\n",
        "Scenario:\n",
        "You need to implement an AND-NOT gate, which outputs 1 only if the first input is 1 and the second input is 0.\n",
        "Lab Task: Design a Single Layer Perceptron in Google Colab to classify the output of an AND-NOT gate. Follow these steps:\n",
        "Create the truth table for the AND-NOT gate.\n",
        "Define a perceptron model with an appropriate activation function.\n",
        "Train the model on the AND-NOT gate dataset.\n",
        "Test the model and analyze its classification accuracy."
      ],
      "metadata": {
        "id": "atJoXB4NypHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step Activation Function\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Perceptron Model\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.5, epochs=50, weights=None, bias=None):\n",
        "        # Allow user to input weights and bias manually or initialize them randomly\n",
        "        if weights is not None:\n",
        "            self.weights = np.array(weights)\n",
        "        else:\n",
        "            self.weights = np.random.rand(input_size)\n",
        "\n",
        "        if bias is not None:\n",
        "            self.bias = bias  # Treat bias as a scalar, no need for array\n",
        "        else:\n",
        "            self.bias = np.random.rand(1)[0]  # Initialize bias as a scalar\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    # Predict output for given inputs\n",
        "    def predict(self, inputs):\n",
        "        linear_output = np.dot(inputs, self.weights) + self.bias\n",
        "        return step_function(linear_output)\n",
        "\n",
        "    # Train the model\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            all_correct = True  # Flag to track if all predictions are correct\n",
        "            print(f\"\\nEpoch {epoch + 1}\")\n",
        "            for inputs, target in zip(X, y):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = target - prediction\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.weights += self.learning_rate * error * inputs\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "                # Print current weights, bias, and output prediction (formatted to 2 decimal places)\n",
        "                print(f\"Input: {inputs}, Predicted Output: {prediction}, Actual Output: {target}, \"\n",
        "                      f\"Weights: {np.round(self.weights, 2)}, Bias: {round(self.bias, 2)}\")\n",
        "\n",
        "                # If there's an error, set all_correct to False\n",
        "                if error != 0:\n",
        "                    all_correct = False\n",
        "\n",
        "            # If all predictions were correct, exit early\n",
        "            if all_correct:\n",
        "                print(f\"\\nTraining complete after epoch {epoch + 1} (All predictions correct).\")\n",
        "                break\n",
        "\n",
        "# Dataset: XOR gate truth table\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs for XOR gate\n",
        "y = np.array([0, 1, 1, 0])  # Corresponding outputs for XOR gate\n",
        "\n",
        "# User input for initial weights and bias\n",
        "input_weights = [float(x) for x in input(\"Enter initial weights (comma separated): \").split(\",\")]\n",
        "input_bias = float(input(\"Enter initial bias: \"))\n",
        "\n",
        "# Initialize and train the perceptron with manual weights and bias\n",
        "perceptron = Perceptron(input_size=2, learning_rate=0.1, epochs=50, weights=input_weights, bias=input_bias)\n",
        "perceptron.train(X, y)\n",
        "\n",
        "# Test the perceptron\n",
        "print(\"\\nTesting XOR Gate Perceptron:\")\n",
        "for inputs in X:\n",
        "    output = perceptron.predict(inputs)\n",
        "    print(f\"Input: {inputs}, Predicted Output: {output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFyc4zFhyviE",
        "outputId": "260b2f0e-46c1-4538-ca06-c4f71bdf59e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter initial weights (comma separated): 1.2, 2.3\n",
            "Enter initial bias: 2.1\n",
            "\n",
            "Epoch 1\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [1.2 2.3], Bias: 2.0\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [1.2 2.3], Bias: 2.0\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [1.2 2.3], Bias: 2.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [1.1 2.2], Bias: 1.9\n",
            "\n",
            "Epoch 2\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [1.1 2.2], Bias: 1.8\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [1.1 2.2], Bias: 1.8\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [1.1 2.2], Bias: 1.8\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [1.  2.1], Bias: 1.7\n",
            "\n",
            "Epoch 3\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [1.  2.1], Bias: 1.6\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [1.  2.1], Bias: 1.6\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [1.  2.1], Bias: 1.6\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.9 2. ], Bias: 1.5\n",
            "\n",
            "Epoch 4\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.9 2. ], Bias: 1.4\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.9 2. ], Bias: 1.4\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.9 2. ], Bias: 1.4\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.8 1.9], Bias: 1.3\n",
            "\n",
            "Epoch 5\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.8 1.9], Bias: 1.2\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.8 1.9], Bias: 1.2\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.8 1.9], Bias: 1.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.7 1.8], Bias: 1.1\n",
            "\n",
            "Epoch 6\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.7 1.8], Bias: 1.0\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.7 1.8], Bias: 1.0\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.7 1.8], Bias: 1.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.6 1.7], Bias: 0.9\n",
            "\n",
            "Epoch 7\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.6 1.7], Bias: 0.8\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.6 1.7], Bias: 0.8\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.6 1.7], Bias: 0.8\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.5 1.6], Bias: 0.7\n",
            "\n",
            "Epoch 8\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.5 1.6], Bias: 0.6\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.5 1.6], Bias: 0.6\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.5 1.6], Bias: 0.6\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.4 1.5], Bias: 0.5\n",
            "\n",
            "Epoch 9\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.4 1.5], Bias: 0.4\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.4 1.5], Bias: 0.4\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.4 1.5], Bias: 0.4\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.3 1.4], Bias: 0.3\n",
            "\n",
            "Epoch 10\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.3 1.4], Bias: 0.2\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.3 1.4], Bias: 0.2\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.3 1.4], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.2 1.3], Bias: 0.1\n",
            "\n",
            "Epoch 11\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [0.2 1.3], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.2 1.3], Bias: -0.0\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.2 1.3], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 1.2], Bias: -0.1\n",
            "\n",
            "Epoch 12\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 1.2], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 1.2], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 1.2], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 1.1], Bias: -0.1\n",
            "\n",
            "Epoch 13\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 1.1], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 1.1], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 1.1], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 1. ], Bias: -0.1\n",
            "\n",
            "Epoch 14\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 1. ], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 1. ], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 1. ], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.9], Bias: -0.1\n",
            "\n",
            "Epoch 15\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.9], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.9], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.8], Bias: -0.1\n",
            "\n",
            "Epoch 16\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.8], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.8], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.8], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.7], Bias: -0.1\n",
            "\n",
            "Epoch 17\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.7], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.7], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.7], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.6], Bias: -0.1\n",
            "\n",
            "Epoch 18\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.6], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.6], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.6], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.5], Bias: -0.1\n",
            "\n",
            "Epoch 19\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.5], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.5], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.5], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.4], Bias: -0.1\n",
            "\n",
            "Epoch 20\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.4], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.4], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.4], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.3], Bias: -0.1\n",
            "\n",
            "Epoch 21\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.3], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.3], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.3], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.2], Bias: -0.1\n",
            "\n",
            "Epoch 22\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.2], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.2], Bias: -0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.2 0.2], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.1 0.1], Bias: -0.1\n",
            "\n",
            "Epoch 23\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.1 0.1], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [0.1 0.2], Bias: -0.0\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.1 0.2], Bias: -0.0\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.  0.1], Bias: -0.1\n",
            "\n",
            "Epoch 24\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.  0.1], Bias: -0.1\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.2], Bias: -0.0\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.1 0.2], Bias: 0.1\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [0.  0.1], Bias: -0.0\n",
            "\n",
            "Epoch 25\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [0.  0.1], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 1, Actual Output: 1, Weights: [0.  0.1], Bias: -0.0\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.1 0.1], Bias: 0.1\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [ 0. -0.], Bias: -0.0\n",
            "\n",
            "Epoch 26\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [ 0. -0.], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 1, Actual Output: 1, Weights: [0.  0.1], Bias: 0.1\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "\n",
            "Epoch 27\n",
            "Input: [0 0], Predicted Output: 0, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 28\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 29\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 30\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 31\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 32\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 33\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 34\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 35\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 36\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 37\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 38\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 39\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 40\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 41\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 42\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 43\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 44\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 45\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 46\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 47\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 48\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 49\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Epoch 50\n",
            "Input: [0 0], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: -0.0\n",
            "Input: [0 1], Predicted Output: 0, Actual Output: 1, Weights: [-0.1  0.1], Bias: 0.1\n",
            "Input: [1 0], Predicted Output: 0, Actual Output: 1, Weights: [0.  0.1], Bias: 0.2\n",
            "Input: [1 1], Predicted Output: 1, Actual Output: 0, Weights: [-0.1 -0. ], Bias: 0.1\n",
            "\n",
            "Testing XOR Gate Perceptron:\n",
            "Input: [0 0], Predicted Output: 1\n",
            "Input: [0 1], Predicted Output: 1\n",
            "Input: [1 0], Predicted Output: 0\n",
            "Input: [1 1], Predicted Output: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XOR Gate Classification\n",
        "Scenario:\n",
        "The XOR gate is known for its complexity, as it outputs 1 only when the inputs are different. This is a challenge for a Single Layer Perceptron since XOR is not linearly separable.\n",
        "Lab Task: Attempt to implement a Single Layer Perceptron in Google Colab to classify the output of an XOR gate. Perform the following steps:\n",
        "Create the XOR gate's truth table dataset.\n",
        "Implement the perceptron model and train it using the XOR dataset.\n",
        "Observe and discuss the perceptron's performance in this scenario."
      ],
      "metadata": {
        "id": "t_qAV8TLzWFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Create MLP model with one hidden layer\n",
        "model = MLPClassifier(hidden_layer_sizes=(2,), activation='relu', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(X)\n",
        "print(\"Testing XOR Gate MLP:\")\n",
        "for inputs, pred in zip(X, predictions):\n",
        "    print(f\"Input: {inputs}, Predicted Output: {pred}\")\n"
      ],
      "metadata": {
        "id": "8uQJc3VTzcGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc06c83c-7e32-43f3-8800-471686c3cfe0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing XOR Gate MLP:\n",
            "Input: [0 0], Predicted Output: 1\n",
            "Input: [0 1], Predicted Output: 1\n",
            "Input: [1 0], Predicted Output: 1\n",
            "Input: [1 1], Predicted Output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Why does the Single Layer Perceptron struggle to classify the XOR gate?\n",
        "\n",
        "Single Layer Perceptron Limitation: An SLP can only create linear decision boundaries. This means it can only classify problems that are linearly separable. It computes the output as:\n",
        "\n",
        "Output=Activation(Weights⋅Input+Bias)\n",
        "\n",
        "The decision boundary is a straight line (or hyperplane in higher dimensions).\n",
        "\n",
        "XOR Gate Non-Linearity: The XOR gate requires a decision boundary that can curve or bend to separate the two classes, which a single line cannot achieve."
      ],
      "metadata": {
        "id": "EUnKYDEc0WZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What modifications can be made to the neural network model to handle the XOR gate correctly?\n",
        "\n",
        "To classify the XOR gate correctly, we need a more complex model like a Multi-Layer Perceptron (MLP) with at least one hidden layer. An MLP can create non-linear decision boundaries by combining multiple linear boundaries through hidden layers, enabling it to solve non-linearly separable problems like XOR."
      ],
      "metadata": {
        "id": "1Dd47D3c5FiX"
      }
    }
  ]
}